{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from nets.frcnn import FasterRCNN\n",
    "from nets.frcnn_training import (FasterRCNNTrainer, get_lr_scheduler,\n",
    "                                 set_optimizer_lr, weights_init)\n",
    "from utils.callbacks import LossHistory\n",
    "from utils.dataloader import FRCNNDataset, frcnn_dataset_collate\n",
    "from utils.utils import get_classes, show_config\n",
    "from utils.utils_fit import fit_one_epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n",
      "initialize network with normal type\n",
      "Load weights model_data/voc_weights_resnet.pth.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/100:   0%|          | 0/4137 [00:00<?, ?it/s<class 'dict'>]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successful Load Key: ['extractor.0.weight', 'extractor.1.weight', 'extractor.1.bias', 'extractor.1.running_mean', 'extractor.1.running_var', 'extractor.1.num_batches_tracked', 'extractor.4.0.conv1.weight', 'extractor.4.0.bn1.weight', 'extractor.4.0.bn1.bias', 'extractor.4.0.bn1.running_mean', 'extractor.4.0.bn1.running_var', 'extractor.4.0.bn1.num_batches_tracked', 'extractor.4.0.conv2.weight', 'extractor.4.0.bn2.weight', 'extractor.4.0.bn2.bias', 'extractor.4.0.bn2.running_mean', 'extractor.4.0.bn2.running_var', 'e ……\n",
      "Successful Load Key Num: 328\n",
      "\n",
      "Fail To Load Key: [] ……\n",
      "Fail To Load Key num: 0\n",
      "\n",
      "\u001b[1;33;44m温馨提示，head部分没有载入是正常现象，Backbone部分没有载入是错误的。\u001b[0m\n",
      "Configurations:\n",
      "----------------------------------------------------------------------\n",
      "|                     keys |                                   values|\n",
      "----------------------------------------------------------------------\n",
      "|             classes_path |               model_data/voc_classes.txt|\n",
      "|               model_path |        model_data/voc_weights_resnet.pth|\n",
      "|              input_shape |                               [600, 600]|\n",
      "|               Init_Epoch |                                        0|\n",
      "|             Freeze_Epoch |                                       50|\n",
      "|           UnFreeze_Epoch |                                      100|\n",
      "|        Freeze_batch_size |                                        4|\n",
      "|      Unfreeze_batch_size |                                        2|\n",
      "|             Freeze_Train |                                     True|\n",
      "|                  Init_lr |                                   0.0001|\n",
      "|                   Min_lr |                   1.0000000000000002e-06|\n",
      "|           optimizer_type |                                     adam|\n",
      "|                 momentum |                                      0.9|\n",
      "|            lr_decay_type |                                      cos|\n",
      "|              save_period |                                        5|\n",
      "|                 save_dir |                                     logs|\n",
      "|              num_workers |                                        4|\n",
      "|                num_train |                                    16551|\n",
      "|                  num_val |                                     4952|\n",
      "----------------------------------------------------------------------\n",
      "Start Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 4137/4137 [1:24:00<00:00,  1.22s/it, lr=1e-5, roi_cls=0.177, roi_loc=0.561, rpn_cls=0.0375, rpn_loc=0.0617, total_loss=0.838]\n",
      "Epoch 1/100:   0%|          | 0/1238 [00:00<?, ?it/s<class 'dict'>]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Train\n",
      "Start Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 1238/1238 [12:34<00:00,  1.64it/s, val_loss=0.986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Validation\n",
      "Epoch:1/100\n",
      "Total Loss: 0.838 || Val Loss: 0.986 \n",
      "Save best model to best_epoch_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 2/100:   0%|          | 0/4137 [00:00<?, ?it/s<class 'dict'>]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 4137/4137 [1:24:06<00:00,  1.22s/it, lr=2e-5, roi_cls=0.18, roi_loc=0.564, rpn_cls=0.0376, rpn_loc=0.0594, total_loss=0.84]  \n",
      "Epoch 2/100:   0%|          | 0/1238 [00:00<?, ?it/s<class 'dict'>]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Train\n",
      "Start Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 1238/1238 [13:10<00:00,  1.57it/s, val_loss=0.991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Validation\n",
      "Epoch:2/100\n",
      "Total Loss: 0.840 || Val Loss: 0.991 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3/100:   0%|          | 0/4137 [00:00<?, ?it/s<class 'dict'>]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100:  33%|███▎      | 1375/4137 [28:04<55:46,  1.21s/it, lr=5e-5, roi_cls=0.192, roi_loc=0.61, rpn_cls=0.0375, rpn_loc=0.0646, total_loss=0.904]   "
     ]
    }
   ],
   "source": [
    "Cuda            = True\n",
    "train_gpu       = [0,]\n",
    "fp16            = False\n",
    "classes_path    = 'model_data/voc_classes.txt'\n",
    "model_path      = 'model_data/voc_weights_resnet.pth'\n",
    "input_shape     = [600, 600]\n",
    "backbone        = \"resnet50\"\n",
    "pretrained      = False\n",
    "anchors_size    = [8, 16, 32]\n",
    "\n",
    "UnFreeze_Epoch      = 100\n",
    "Unfreeze_batch_size = 2\n",
    "Freeze_Train        = True\n",
    "Init_lr             = 1e-4\n",
    "Min_lr              = Init_lr * 0.01\n",
    "optimizer_type      = \"adam\"\n",
    "momentum            = 0.9\n",
    "weight_decay        = 0\n",
    "lr_decay_type       = 'cos'\n",
    "save_period         = 5\n",
    "save_dir            = 'logs'\n",
    "num_workers         = 4\n",
    "train_annotation_path   = '2007_train.txt'\n",
    "val_annotation_path     = '2007_val.txt'\n",
    "\n",
    "class_names, num_classes = get_classes(classes_path)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]  = ','.join(str(x) for x in train_gpu)\n",
    "ngpus_per_node                      = len(train_gpu)\n",
    "print('Number of devices: {}'.format(ngpus_per_node))\n",
    "\n",
    "model = FasterRCNN(num_classes, anchor_scales = anchors_size, backbone = backbone, pretrained = pretrained)\n",
    "if not pretrained:\n",
    "    weights_init(model)\n",
    "if model_path != '':\n",
    "    print('Load weights {}.'.format(model_path))\n",
    "\n",
    "    device          = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_dict      = model.state_dict()\n",
    "    pretrained_dict = torch.load(model_path, map_location = device)\n",
    "    load_key, no_load_key, temp_dict = [], [], {}\n",
    "    for k, v in pretrained_dict.items():\n",
    "        if k in model_dict.keys() and np.shape(model_dict[k]) == np.shape(v):\n",
    "            temp_dict[k] = v\n",
    "            load_key.append(k)\n",
    "        else:\n",
    "            no_load_key.append(k)\n",
    "    model_dict.update(temp_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "loss_history = LossHistory(save_dir, model, input_shape=input_shape)\n",
    "\n",
    "if fp16:\n",
    "    from torch.cuda.amp import GradScaler as GradScaler\n",
    "    scaler = GradScaler()\n",
    "else:\n",
    "    scaler = None\n",
    "\n",
    "model_train     = model.train()\n",
    "if Cuda:\n",
    "    model_train = torch.nn.DataParallel(model_train)\n",
    "    cudnn.benchmark = True\n",
    "    model_train = model_train.cuda()\n",
    "\n",
    "with open(train_annotation_path, encoding='utf-8') as f:\n",
    "    train_lines = f.readlines()\n",
    "with open(val_annotation_path, encoding='utf-8') as f:\n",
    "    val_lines   = f.readlines()\n",
    "num_train   = len(train_lines)\n",
    "num_val     = len(val_lines)\n",
    "\n",
    "show_config(\n",
    "    classes_path = classes_path, model_path = model_path, input_shape = input_shape, \\\n",
    "    Init_Epoch = Init_Epoch, Freeze_Epoch = Freeze_Epoch, UnFreeze_Epoch = UnFreeze_Epoch, Freeze_batch_size = Freeze_batch_size, Unfreeze_batch_size = Unfreeze_batch_size, Freeze_Train = Freeze_Train, \\\n",
    "    Init_lr = Init_lr, Min_lr = Min_lr, optimizer_type = optimizer_type, momentum = momentum, lr_decay_type = lr_decay_type, \\\n",
    "    save_period = save_period, save_dir = save_dir, num_workers = num_workers, num_train = num_train, num_val = num_val\n",
    ")\n",
    "wanted_step = 5e4 if optimizer_type == \"sgd\" else 1.5e4\n",
    "total_step  = num_train // Unfreeze_batch_size * UnFreeze_Epoch\n",
    "if total_step <= wanted_step:\n",
    "    wanted_epoch = wanted_step // (num_train // Unfreeze_batch_size) + 1\n",
    "    \n",
    "if True:\n",
    "    UnFreeze_flag = False\n",
    "    if Freeze_Train:\n",
    "        for param in model.extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "    model.freeze_bn()\n",
    "\n",
    "    batch_size = Freeze_batch_size if Freeze_Train else Unfreeze_batch_size\n",
    "\n",
    "    nbs             = 16\n",
    "    lr_limit_max    = 1e-4 if optimizer_type == 'adam' else 5e-2\n",
    "    lr_limit_min    = 1e-4 if optimizer_type == 'adam' else 5e-4\n",
    "    Init_lr_fit     = min(max(batch_size / nbs * Init_lr, lr_limit_min), lr_limit_max)\n",
    "    Min_lr_fit      = min(max(batch_size / nbs * Min_lr, lr_limit_min * 1e-2), lr_limit_max * 1e-2)\n",
    "\n",
    "    optimizer = {\n",
    "        'adam'  : optim.Adam(model.parameters(), Init_lr_fit, betas = (momentum, 0.999), weight_decay = weight_decay),\n",
    "        'sgd'   : optim.SGD(model.parameters(), Init_lr_fit, momentum = momentum, nesterov=True, weight_decay = weight_decay)\n",
    "    }[optimizer_type]\n",
    "\n",
    "    lr_scheduler_func = get_lr_scheduler(lr_decay_type, Init_lr_fit, Min_lr_fit, UnFreeze_Epoch)\n",
    "\n",
    "    epoch_step      = num_train // batch_size\n",
    "    epoch_step_val  = num_val // batch_size\n",
    "\n",
    "    if epoch_step == 0 or epoch_step_val == 0:\n",
    "        raise ValueError(\"数据集过小，无法继续进行训练，请扩充数据集。\")\n",
    "\n",
    "    train_dataset   = FRCNNDataset(train_lines, input_shape, train = True)\n",
    "    val_dataset     = FRCNNDataset(val_lines, input_shape, train = False)\n",
    "\n",
    "    gen             = DataLoader(train_dataset, shuffle = True, batch_size = batch_size, num_workers = num_workers, pin_memory=True,\n",
    "                                drop_last=True, collate_fn=frcnn_dataset_collate)\n",
    "    gen_val         = DataLoader(val_dataset  , shuffle = True, batch_size = batch_size, num_workers = num_workers, pin_memory=True, \n",
    "                                drop_last=True, collate_fn=frcnn_dataset_collate)\n",
    "\n",
    "    train_util      = FasterRCNNTrainer(model_train, optimizer)\n",
    "\n",
    "    for epoch in range(Init_Epoch, UnFreeze_Epoch):\n",
    "        if epoch >= Freeze_Epoch and not UnFreeze_flag and Freeze_Train:\n",
    "            batch_size = Unfreeze_batch_size\n",
    "\n",
    "            nbs             = 16\n",
    "            lr_limit_max    = 1e-4 if optimizer_type == 'adam' else 5e-2\n",
    "            lr_limit_min    = 1e-4 if optimizer_type == 'adam' else 5e-4\n",
    "            Init_lr_fit     = min(max(batch_size / nbs * Init_lr, lr_limit_min), lr_limit_max)\n",
    "            Min_lr_fit      = min(max(batch_size / nbs * Min_lr, lr_limit_min * 1e-2), lr_limit_max * 1e-2)\n",
    "\n",
    "            lr_scheduler_func = get_lr_scheduler(lr_decay_type, Init_lr_fit, Min_lr_fit, UnFreeze_Epoch)\n",
    "\n",
    "            for param in model.extractor.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            model.freeze_bn()\n",
    "\n",
    "            epoch_step      = num_train // batch_size\n",
    "            epoch_step_val  = num_val // batch_size\n",
    "\n",
    "            if epoch_step == 0 or epoch_step_val == 0:\n",
    "                raise ValueError(\"数据集过小，无法继续进行训练，请扩充数据集。\")\n",
    "\n",
    "            gen             = DataLoader(train_dataset, shuffle = True, batch_size = batch_size, num_workers = num_workers, pin_memory=True,\n",
    "                                        drop_last=True, collate_fn=frcnn_dataset_collate)\n",
    "            gen_val         = DataLoader(val_dataset  , shuffle = True, batch_size = batch_size, num_workers = num_workers, pin_memory=True, \n",
    "                                        drop_last=True, collate_fn=frcnn_dataset_collate)\n",
    "\n",
    "            UnFreeze_flag = True\n",
    "\n",
    "        set_optimizer_lr(optimizer, lr_scheduler_func, epoch)\n",
    "\n",
    "        fit_one_epoch(model, train_util, loss_history, optimizer, epoch, epoch_step, epoch_step_val, gen, gen_val, UnFreeze_Epoch, Cuda, fp16, scaler, save_period, save_dir)\n",
    "\n",
    "    loss_history.writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python pytorch",
   "language": "python",
   "name": "pytoch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
